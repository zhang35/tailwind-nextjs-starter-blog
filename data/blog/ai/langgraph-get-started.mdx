---
title: Getting Started with LangGraph
date: '2025-08-10'
tags: ['ai', 'langgraph']
draft: false
---

LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain ecosystem, allowing you to model agent workflows as graphs. This approach provides more control and flexibility for creating complex, cyclical, and long-running agentic systems.

Let's dive into the fundamental concepts.

## Core Concepts of LangGraph

At its core, LangGraph represents workflows using three main components: State, Nodes, and Edges.

### State

The **State** is a shared data structure that represents the current snapshot of your application. It's the memory or the "state" of your graph that gets passed between nodes.

- It can be any Python type, but is typically a `TypedDict` or a Pydantic `BaseModel` for structured data.
- The state is updated by nodes throughout the execution of the graph.

### Nodes

**Nodes** are the workhorses of the graph. They are Python functions that contain the logic for your agents or tools.

- Each node receives the current `State` as input.
- It performs some computation, calls a tool, or interacts with an LLM.
- It returns an updated `State` object. **Crucially, whatever a node returns is used to update the graph's central state.**

### Edges

**Edges** connect the nodes and direct the flow of logic. They are Python functions that determine which node to execute next based on the current `State`.

- Edges can represent fixed transitions (e.g., Node A always goes to Node B).
- They can also create conditional branches, allowing for dynamic, state-driven routing within the graph (e.g., if the state contains an error, go to a fallback node).

In short: **Nodes do the work, and Edges decide what to do next.**

## Agent Input and Output

Understanding how to interact with a LangGraph agent is key.

### Input Format

Agent input must be a dictionary containing a `messages` key. The value can be in several formats, which LangGraph automatically converts into LangChain's internal message format.

| Format             | Example                                                | Interpretation                                         |
| ------------------ | ------------------------------------------------------ | ------------------------------------------------------ |
| String             | `{"messages": "Hello"}`                                | Interpreted as a `HumanMessage`.                       |
| Message Dictionary | `{"messages": {"role": "user", "content": "Hello"}}`   | A single message object.                               |
| List of Messages   | `{"messages": [{"role": "user", "content": "Hello"}]}` | A sequence of messages.                                |
| With Custom State  | `{"messages": [...], "user_name": "Alice"}`            | Includes additional fields from a custom state schema. |

> **Note:** A simple string input for `messages` is converted to a `HumanMessage`. This differs from the `prompt` parameter in `create_react_agent`, which is interpreted as a `SystemMessage` when passed as a string.

### Output Format

The output from a LangGraph agent is also a dictionary, which will contain:

- `messages`: A list of all messages exchanged during the execution, including user inputs, assistant replies, and tool invocations.
- **Custom State Fields**: If you're using a custom `state_schema`, any fields you defined may also be present in the output, holding their final values.
- `structured_response`: This key may be present if you have configured structured output for your agent.

By understanding these core components, you can start building powerful and predictable agentic workflows with LangGraph.
